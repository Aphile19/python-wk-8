# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
import re
from datetime import datetime

# Load the data
df = pd.read_csv('../data/metadata.csv')

# Basic exploration
print("Dataset shape:", df.shape)
print("\nColumn names:")
print(df.columns.tolist())
print("\nData types:")
print(df.dtypes)
print("\nMissing values:")
print(df.isnull().sum())
print("\nBasic statistics:")
print(df.describe())

# Create a copy for cleaning
df_clean = df.copy()

# Check important columns for missing values
important_cols = ['title', 'abstract', 'publish_time', 'journal', 'authors']
for col in important_cols:
    missing_percent = df_clean[col].isnull().mean() * 100
    print(f"{col}: {missing_percent:.2f}% missing")

# Handle missing values
# For title, we'll drop rows with missing titles as they're crucial
df_clean = df_clean.dropna(subset=['title'])

# For abstract, we'll fill with "No abstract available"
df_clean['abstract'] = df_clean['abstract'].fillna('No abstract available')

# For publish_time, we'll extract year where possible
def extract_year(date_str):
    if pd.isnull(date_str):
        return np.nan
    try:
        # Try to convert to datetime
        if isinstance(date_str, str):
            # Handle various date formats
            if len(date_str) == 4:  # Just year
                return int(date_str)
            else:
                # Try to parse as date
                date_obj = pd.to_datetime(date_str, errors='coerce')
                if pd.isnull(date_obj):
                    # Try to extract year from string
                    year_match = re.search(r'\d{4}', date_str)
                    if year_match:
                        return int(year_match.group())
                    else:
                        return np.nan
                else:
                    return date_obj.year
        else:
            return np.nan
    except:
        return np.nan

df_clean['year'] = df_clean['publish_time'].apply(extract_year)

# Drop rows where we couldn't extract a year
df_clean = df_clean.dropna(subset=['year'])
df_clean['year'] = df_clean['year'].astype(int)

# For journal, fill with "Unknown"
df_clean['journal'] = df_clean['journal'].fillna('Unknown')

# For authors, fill with "Unknown authors"
df_clean['authors'] = df_clean['authors'].fillna('Unknown authors')

# Create new features
df_clean['abstract_word_count'] = df_clean['abstract'].apply(lambda x: len(str(x).split()))
df_clean['title_word_count'] = df_clean['title'].apply(lambda x: len(str(x).split()))

# Check the cleaned data
print("Cleaned dataset shape:", df_clean.shape)
print("\nMissing values after cleaning:")

# Set style for visualizations
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (12, 8)

# 1. Publications over time
year_counts = df_clean['year'].value_counts().sort_index()
plt.figure(figsize=(14, 7))
plt.bar(year_counts.index, year_counts.values)
plt.title('Number of Publications by Year')
plt.xlabel('Year')
plt.ylabel('Number of Publications')
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig('../publications_by_year.png')
plt.show()

# 2. Top journals
top_journals = df_clean['journal'].value_counts().head(15)
plt.figure(figsize=(14, 10))
sns.barplot(y=top_journals.index, x=top_journals.values)
plt.title('Top 15 Journals by Number of Publications')
plt.xlabel('Number of Publications')
plt.tight_layout()
plt.savefig('../top_journals.png')
plt.show()

# 3. Word cloud of titles
# Combine all titles
all_titles = ' '.join(df_clean['title'].dropna().astype(str))

# Generate word cloud
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_titles)

plt.figure(figsize=(16, 8))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud of Paper Titles')
plt.tight_layout()
plt.savefig('../title_wordcloud.png')
plt.show()

# 4. Distribution of abstract word count
plt.figure(figsize=(12, 6))
sns.histplot(df_clean['abstract_word_count'], bins=50, kde=True)
plt.title('Distribution of Abstract Word Count')
plt.xlabel('Word Count')
plt.xlim(0, 500)  # Limit x-axis to make it more readable
plt.tight_layout()
plt.savefig('../abstract_wordcount.png')
plt.show()

# 5. Publications by source
top_sources = df_clean['source_x'].value_counts().head(10)
plt.figure(figsize=(12, 8))
sns.barplot(y=top_sources.index, x=top_sources.values)
plt.title('Top 10 Sources by Number of Publications')
plt.xlabel('Number of Publications')
plt.tight_layout()
plt.savefig('../top_sources.png')
plt.show()
print(df_clean[important_cols].isnull().sum())
